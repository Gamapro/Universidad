{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available(): return torch.device('cuda')\n",
    "    else: return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, conv, dense, device, channels=3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.device = device\n",
    "        self.channels = channels\n",
    "        self.dim = channels\n",
    "        convs, rests, linears = [],[],[]\n",
    "        doble, same, fin = (4,2,1), (3,1,1), (4,1,0)\n",
    "        for i in range(len(conv) - 1):\n",
    "            convs.append(  self.ConvLayer( conv[i], conv[i+1], values=doble, pool=True) )\n",
    "            rests.append(  self.RestLayer( conv[i+1]) )\n",
    "        self.flatten = nn.Flatten()\n",
    "        for i in range(len(dense) - 1):\n",
    "            linears.append(self.LinearLayer(dense[i], dense[i+1], output=(i+2==len(dense))  ))\n",
    "        self.conv_layers = nn.Sequential(*convs)\n",
    "        self.rest_layers = nn.Sequential(*rests)\n",
    "        self.linear_layers = nn.Sequential(*linears)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, rest in zip(self.conv_layers, self.rest_layers):\n",
    "            x = conv(x)\n",
    "            x = rest(x) + x\n",
    "        x = self.flatten(x)\n",
    "        for layer in self.linear_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def LinearLayer(self, in_size, out_size, output=False):\n",
    "        layers = [ nn.Linear(in_size, out_size, device=self.device) ]\n",
    "        if not output:\n",
    "            layers.extend( [nn.BatchNorm1d(out_size),\n",
    "                            nn.ReLU(inplace=True)] )\n",
    "        else:\n",
    "            layers.append( nn.Softmax(dim=1) )\n",
    "            \n",
    "        return nn.Sequential( *layers )\n",
    "\n",
    "    def ConvLayer(self, in_size, out_size, values=(3,1,1), pool=False, output=False, batch=True):\n",
    "        kernel, stride, padding = values\n",
    "        layers = [  nn.Conv2d(in_size, out_size, kernel_size=kernel, stride=stride, padding=padding, bias=False, device=self.device),\n",
    "                    nn.BatchNorm2d(out_size), \n",
    "                    nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if pool:  layers.append( nn.MaxPool2d(2, 2) )\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def RestLayer(self, size, values=(3,1,1)):\n",
    "        return nn.Sequential( self.ConvLayer(size, size, values), self.ConvLayer(size, size, values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredArray(predi, classes):\n",
    "\n",
    "    vals, d = [], dict()\n",
    "    for i,x in enumerate(predi):\n",
    "        cosa = [ classes[i] for _ in range(int(x*100) + 1) ]\n",
    "        vals.extend( cosa )\n",
    "    d['values'] = vals\n",
    "\n",
    "    vals_df = pd.DataFrame(np.array([vals,vals]).T , columns=['values','other'])\n",
    "\n",
    "    return vals, d, vals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDim(img, val=(512,512)):\n",
    "    dim = val\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackTensors(input):\n",
    "    input = torch.unsqueeze(input, 0)\n",
    "    input = torch.concat( (input, input) , 0)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImg(img, dim=(512, 512)):\n",
    "\n",
    "    resized = toDim(img, dim)\n",
    "\n",
    "    resized = (resized - np.min(resized)) / (np.max(resized) - np.min(resized)) * 2 - 1\n",
    "\n",
    "    input = torch.tensor(resized, dtype=torch.float32)\n",
    "    input = torch.unsqueeze(torch.moveaxis(input, 2, 0), 0)\n",
    "    input = torch.concat( (input, input) , 0)\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )\n",
    "dim = (256, 512)\n",
    "# dim = (512, 512)\n",
    "test_tfms = tt.Compose([\n",
    "                        tt.ToPILImage(),    \n",
    "                        tt.Resize(dim), \n",
    "                        tt.ToTensor(),\n",
    "                        tt.Normalize(*normalized_stats,inplace=True)\n",
    "])\n",
    "\n",
    "#classes = ['100', '20', '200', '50', '500']\n",
    "classes = ['20', '100', '200', '50', '500']\n",
    "\n",
    "def predict(img):\n",
    "\n",
    "    input = test_tfms(img)\n",
    "    input_copy = input.detach().numpy().copy()\n",
    "    input = stackTensors(input)\n",
    "\n",
    "    pred = model(input)\n",
    "    predi = pred.detach().numpy().copy()\n",
    "    _, pred = torch.max(pred, dim=1)\n",
    "    s = classes[pred[0]]\n",
    "    \n",
    "    return predi, pred, s, input_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rects(img):\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "  #ret, imgt = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "  ret, imgt = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "  countours, hierarchy = cv2.findContours(imgt.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  rectangles = [cv2.boundingRect(countour) for countour in countours]\n",
    "  c = 0\n",
    "  for rect in rectangles:\n",
    "    if rect[2] > 50 and rect[3] > 50:\n",
    "      imgn = img[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]]\n",
    "      imgn = cv2.resize(imgn, (100, 100))\n",
    "      c += 1\n",
    "\n",
    "      # Clasificar la imagen imgn\n",
    "      predi, pred, s, input_copy = predict(imgn)\n",
    "      # Escribir el resultado\n",
    "\n",
    "      cv2.rectangle(img, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (255, 0, 0), 2)\n",
    "      cv2.putText(img, s, (rect[0], rect[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 0, 0), 3, cv2.LINE_AA)\n",
    "  return img, imgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones [0.00326123 0.02387649 0.60870177 0.01839349 0.345767  ]\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#model = torch.load('../models/model-bills-3.0.pth', map_location=device)\n",
    "model = torch.load('../models/model-bills-3.0-95.pth', map_location=device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Webcam\n",
    "webcam = cv2.VideoCapture(0) # En lugar de ingresar la direccion del video, un numero para el id \n",
    "\n",
    "webcam.set(3,600)  # Set width, id 3\n",
    "webcam.set(4,600)  # Set heigth, id 4\n",
    "webcam.set(10,100)  # Set brillo, id 10\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#sizeVideo = (int(webcam.get(3)) , int(webcam.get(4)) )\n",
    "sizeVideo= (500, 500)\n",
    "# videoRecorder = cv2.VideoWriter('videoBilletes.avi', cv2.VideoWriter_fourcc(*'MJPG'), 5, sizeVideo)\n",
    "\n",
    "while True:\n",
    "    success, img = webcam.read()\n",
    "\n",
    "    img_ori = img.copy()\n",
    "    img_rects = img.copy()\n",
    "    \n",
    "    predi, pred, s, input_copy = predict(img)\n",
    "    \n",
    "    img_rects, imgt = rects(img_rects)\n",
    "\n",
    "    print(f'Predicciones {predi[0]}')\n",
    "    print(s)\n",
    "\n",
    "    predictions, dc, d2 = getPredArray(predi[0], classes)\n",
    "    sb.countplot(x='values',data=d2, ax=ax)\n",
    "    fig.savefig('hist.jpg')\n",
    "    ax.clear()\n",
    "\n",
    "    fig_img = cv2.imread(\"hist.jpg\")\n",
    "    # input_copy = np.moveaxis(input_copy,0,2)\n",
    "    imgs = stackImages(0.6, [[img_ori, fig_img], [img_rects, imgt]])\n",
    "    \n",
    "    # videoRecorder.write(cv2.resize(imgs, sizeVideo, interpolation = cv2.INTER_AREA))\n",
    "\n",
    "    cv2.imshow(\"Video\",imgs)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "plt.close()\n",
    "webcam.release()           # Liberar la webcam\n",
    "# videoRecorder.release()\n",
    "cv2.destroyAllWindows()    # Limpiar las ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion(img):\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "  ret, imgt = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "  #cv2.imshow(\"Image threshold\", imgt)\n",
    "  countours, hierarchy = cv2.findContours(imgt.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  rectangles = [cv2.boundingRect(countour) for countour in countours]\n",
    "  c = 0\n",
    "  for rect in rectangles:\n",
    "    if rect[2] > 50 and rect[3] > 50:\n",
    "      imgn = img[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]]\n",
    "      imgn = cv2.resize(imgn, (100, 100))\n",
    "      c += 1\n",
    "      # cv2.imshow(\"Image rect\", imgn)\n",
    "      \n",
    "      # Clasificar la imagen imgn\n",
    "      input = processImg(imgn.copy())\n",
    "      pred = model(input)\n",
    "      _, pred = torch.max(pred, dim=1)\n",
    "      s = classes[pred[0]]\n",
    "\n",
    "      # Escribir el resultado\n",
    "      cv2.rectangle(img, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (255, 0, 0), 2)\n",
    "      cv2.putText(img, s, (rect[0], rect[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 0, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "  imgs = stackImages(0.7, [img, imgt])\n",
    "  # cv2.imshow(\"Video\",imgs)\n",
    "  return imgs\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cont, bill = 0, 500 \n",
    "path = f'test-bill/{bill}'\n",
    "while True:\n",
    "    val, img = cam.read()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        while cv2.waitKey(1) & 0xFF == ord('s'): continue\n",
    "        if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "        cv2.imwrite(os.path.join(path, f'azu-{bill}-{cont}.jpg'), img)\n",
    "        cont+=1\n",
    "    img = funcion(img)\n",
    "    cv2.imshow(\"Image funcion\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eea840d32bf56a928ee27a035e52aac990f88e7d3a2b564ede6a6b77b7629b2f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
